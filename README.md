Abstract: The widespread proliferation of hate speech online underscores the need for effective detection methods to ensure online safety and inclusivity. Conventional models often miss the nuanced contextual and intentional aspects of language. This study proposes an innovative approach integrating pragmatic information into hate speech detection using advanced Large Language Models (LLMs) such as BERT and generative artificial intelligence (GenAI) models like Mistral 7B, Llama 2 7B, and GPT-3. By enriching these models with contextual layers, they gain a deeper understanding of language subtleties. Through fine-tuning and prompt engineering, the models show superior performance compared to standard methods across various metrics and domains. They also exhibit robust generalization capabilities on unseen data. This research not only advances Natural Language Processing (NLP) in hate speech detection but also enhances practical efforts in fostering safer digital environments. It emphasizes the significance of incorporating pragmatic elements in automated content moderation for a more nuanced and effective approach against online hate speech.

